{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9bc955",
   "metadata": {},
   "source": [
    "# FAISS Vector Store Implementation\n",
    "\n",
    "This notebook demonstrates how to set up and use a FAISS vector store with LangChain and OpenAI embeddings. FAISS (Facebook AI Similarity Search) is an efficient similarity search library that allows for quick retrieval of vectors similar to a query vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d452a",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, we'll import all the required libraries and load environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815cf9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871ddb3",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Embeddings\n",
    "\n",
    "Next, we initialize the OpenAI embeddings model that will convert our text into vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c8f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ee568",
   "metadata": {},
   "source": [
    "## Create FAISS Index\n",
    "\n",
    "Now we create a FAISS index with the L2 (Euclidean) distance metric. We need to specify the dimension of our vectors, which we determine by embedding a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35183690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS index with L2 distance metric\n",
    "# We determine the dimension by embedding a sample query\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437470a8",
   "metadata": {},
   "source": [
    "## Initialize FAISS Vector Store\n",
    "\n",
    "Finally, we create the FAISS vector store using our embeddings model and index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13cf6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FAISS vector store\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf08526",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Below are some examples of how to use the FAISS vector store for document storage and similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af795dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edcd9bba-1d5e-4521-a459-46ecc59cb7c4',\n",
       " '6b9f9980-ec02-40e6-80e1-d20c92e177cb',\n",
       " 'ec0a896a-82bc-4189-a3a7-28c5d180d275',\n",
       " 'c3bedc75-f326-4c50-9032-cb4aaead4153',\n",
       " '23080406-6637-461f-b18a-ee941ccf5ec2',\n",
       " '29951a3e-e88f-4322-aeb6-5d800c491ecf',\n",
       " '4077f257-2112-484d-a647-8d92c69c8b13',\n",
       " '67a37c13-8b8f-4128-a107-ee87fc12a55b']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Adding documents to the vector store\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create sample documents\n",
    "documents = [\n",
    "    Document(page_content=\"FAISS is a library for efficient similarity search.\", metadata={\"source\": \"doc1\"}),\n",
    "    Document(page_content=\"Vector databases store embeddings for quick retrieval.\", metadata={\"source\": \"doc2\"}),\n",
    "    Document(page_content=\"LangChain provides tools for building LLM applications.\", metadata={\"source\": \"doc3\"}),\n",
    "    Document(page_content=\"LangChain provides tools for building LLM applications.\", metadata={\"source\": \"tweet\"}),\n",
    "    Document(page_content=\"FAISS can handle large datasets efficiently.\", metadata={\"source\": \"doc4\"}),\n",
    "    Document(page_content=\"OpenAI's embeddings are useful for various NLP tasks.\", metadata={\"source\": \"doc5\"}),\n",
    "    Document(page_content=\"FAISS supports both CPU and GPU for indexing.\", metadata={\"source\": \"tweet\"}),\n",
    "    Document(\n",
    "        page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "        metadata={\"source\": \"news\"},\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60bec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: doc2\n",
      "Content: Vector databases store embeddings for quick retrieval.\n",
      "--------------------------------------------------\n",
      "Source: doc4\n",
      "Content: FAISS can handle large datasets efficiently.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example: Performing a similarity search\n",
    "query = \"How do vector databases work?\"\n",
    "results = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "# Display results\n",
    "for doc in results:\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7c2d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: doc2\n",
      "Content: Vector databases store embeddings for quick retrieval.\n",
      "Similarity Score: 0.6612452268600464\n",
      "--------------------------------------------------\n",
      "Source: doc4\n",
      "Content: FAISS can handle large datasets efficiently.\n",
      "Similarity Score: 1.395352840423584\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example: Performing a similarity search with scores\n",
    "results_with_scores = vector_store.similarity_search_with_score(query, k=2)\n",
    "\n",
    "# Display results with similarity scores\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print(f\"Similarity Score: {score}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37e434",
   "metadata": {},
   "source": [
    "## Query with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e18675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='c3bedc75-f326-4c50-9032-cb4aaead4153', metadata={'source': 'tweet'}, page_content='LangChain provides tools for building LLM applications.'), Document(id='4077f257-2112-484d-a647-8d92c69c8b13', metadata={'source': 'tweet'}, page_content='FAISS supports both CPU and GPU for indexing.')]\n",
      "* LangChain provides tools for building LLM applications. [{'source': 'tweet'}]\n",
      "* FAISS supports both CPU and GPU for indexing. [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "print(results)\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b2803c",
   "metadata": {},
   "source": [
    "Some MongoDB query and projection operators are supported for more advanced metadata filtering. The current list of supported operators are as follows:\n",
    "\n",
    "* $eq (equals)\n",
    "* $neq (not equals)\n",
    "* $gt (greater than)\n",
    "* $lt (less than)\n",
    "* $gte (greater than or equal)\n",
    "* $lte (less than or equal)\n",
    "* $in (membership in list)\n",
    "* $nin (not in list)\n",
    "* $and (all conditions must match)\n",
    "* $or (any condition must match)\n",
    "* $not (negation of condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752200eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* LangChain provides tools for building LLM applications. [{'source': 'tweet'}]\n",
      "* FAISS supports both CPU and GPU for indexing. [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": {\"$eq\": \"tweet\"}},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a1947",
   "metadata": {},
   "source": [
    "## Similarity search with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80d04e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=1.866577] FAISS can handle large datasets efficiently. [{'source': 'doc4'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": {\"$neq\": \"tweet\"}}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86885984",
   "metadata": {},
   "source": [
    "## Query by turning vector store to a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb94e5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='67a37c13-8b8f-4128-a107-ee87fc12a55b', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 1})\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13a496",
   "metadata": {},
   "source": [
    "## Saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63753b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "new_vector_store = FAISS.load_local(\n",
    "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "docs = new_vector_store.similarity_search(\"qux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f89371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='ec0a896a-82bc-4189-a3a7-28c5d180d275', metadata={'source': 'doc3'}, page_content='LangChain provides tools for building LLM applications.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f39ba",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to set up a FAISS vector store using LangChain and OpenAI embeddings. You can extend this implementation by:\n",
    "\n",
    "1. Persisting the vector store to disk\n",
    "2. Loading documents from various sources\n",
    "3. Implementing more complex retrieval strategies\n",
    "4. Integrating with LLMs for question answering\n",
    "\n",
    "For more information, refer to the [FAISS documentation](https://github.com/facebookresearch/faiss) and [LangChain documentation](https://python.langchain.com/docs/integrations/vectorstores/faiss)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
